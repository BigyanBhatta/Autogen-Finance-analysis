{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from autogen import AssistantAgent, UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Tell me a Autogen joke in one line\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I'm glad you asked! Here's an Autogen joke for you:\n",
      "\n",
      "Why did the Autogen programmer break up with their keyboard? Because it didn't understand their auto-completion!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Please let me know if there is anything else you would like assistance with.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Tell me a Autogen joke in one line', 'role': 'assistant'}, {'content': \"I'm glad you asked! Here's an Autogen joke for you:\\n\\nWhy did the Autogen programmer break up with their keyboard? Because it didn't understand their auto-completion!\", 'role': 'user'}, {'content': '', 'role': 'assistant'}, {'content': 'Please let me know if there is anything else you would like assistance with.', 'role': 'user'}], summary='Please let me know if there is anything else you would like assistance with.', cost={'usage_including_cached_inference': {'total_cost': 0.0005815, 'gpt-3.5-turbo-0125': {'cost': 0.0005815, 'prompt_tokens': 1007, 'completion_tokens': 52, 'total_tokens': 1059}}, 'usage_excluding_cached_inference': {'total_cost': 0.0005815, 'gpt-3.5-turbo-0125': {'cost': 0.0005815, 'prompt_tokens': 1007, 'completion_tokens': 52, 'total_tokens': 1059}}}, human_input=['', 'exit'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_config = {'model': 'gpt-3.5-turbo-0125', \"api_key\": os.environ['OPENAI_API_KEY']}\n",
    "assistant = AssistantAgent('assistant', llm_config= llm_config)\n",
    "user_proxy = UserProxyAgent('user_proxy', code_execution_config= False)\n",
    "\n",
    "# start the chat\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message= \"Tell me a Autogen joke in one line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute the generated python code in our local system by enabling the parameter:\n",
    "code_execution_config = {'executor': autogen.coding.LocalCommandlineCodeExecutor(work_dir)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversable Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mStudent_Agent\u001b[0m (to Teacher_Agent):\n",
      "\n",
      "What is Bayes Theorem\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTeacher_Agent\u001b[0m (to Student_Agent):\n",
      "\n",
      "Bayes' theorem is a fundamental concept in probability theory and statistics named after Thomas Bayes. It provides a way to update the probability of a hypothesis based on new evidence or information. \n",
      "\n",
      "Mathematically, Bayes' theorem is expressed as:\n",
      "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
      "\n",
      "where:\n",
      "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred.\n",
      "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred.\n",
      "- \\( P(A) \\) and \\( P(B) \\) are the individual probabilities of events A and B occurring, respectively.\n",
      "\n",
      "Bayes' theorem is commonly used in fields such as machine learning, medical diagnosis, and finance to make decisions based on uncertain information.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mStudent_Agent\u001b[0m (to Teacher_Agent):\n",
      "\n",
      "That's a great explanation of Bayes' theorem! It's a powerful tool that can be applied in various real-world scenarios to make informed decisions. If you have any more questions or need further clarification on this topic or anything else, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTeacher_Agent\u001b[0m (to Student_Agent):\n",
      "\n",
      "Thank you! I'm glad you found the explanation helpful. If you have any more questions about mathematics or any other topic, please feel free to ask. I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "student_agent = ConversableAgent(\n",
    "    name ='Student_Agent',\n",
    "    system_message= \"You're a student\",\n",
    "    llm_config = {'config_list': [{'model': 'gpt-3.5-turbo-0125', 'api_key': os.environ['OPENAI_API_KEY']}]}\n",
    ")\n",
    "\n",
    "teacher_agent = ConversableAgent(\n",
    "    name = 'Teacher_Agent', \n",
    "    system_message= \"You are a math teacher\",\n",
    "    llm_config= {'config_list': [{'model': 'gpt-3.5-turbo-0125', 'api_key': os.environ['OPENAI_API_KEY']}]}\n",
    ")\n",
    "\n",
    "chat_result = student_agent.initiate_chat(\n",
    "    teacher_agent,\n",
    "    message= \"What is Bayes Theorem\",\n",
    "    summary_method='reflection_with_llm',\n",
    "    max_turns=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'What is Bayes Theorem', 'role': 'assistant'},\n",
      " {'content': \"Bayes' theorem is a fundamental concept in probability theory \"\n",
      "             'and statistics named after Thomas Bayes. It provides a way to '\n",
      "             'update the probability of a hypothesis based on new evidence or '\n",
      "             'information. \\n'\n",
      "             '\\n'\n",
      "             \"Mathematically, Bayes' theorem is expressed as:\\n\"\n",
      "             '\\\\[ P(A|B) = \\\\frac{P(B|A) \\\\times P(A)}{P(B)} \\\\]\\n'\n",
      "             '\\n'\n",
      "             'where:\\n'\n",
      "             '- \\\\( P(A|B) \\\\) is the probability of event A occurring given '\n",
      "             'that event B has occurred.\\n'\n",
      "             '- \\\\( P(B|A) \\\\) is the probability of event B occurring given '\n",
      "             'that event A has occurred.\\n'\n",
      "             '- \\\\( P(A) \\\\) and \\\\( P(B) \\\\) are the individual probabilities '\n",
      "             'of events A and B occurring, respectively.\\n'\n",
      "             '\\n'\n",
      "             \"Bayes' theorem is commonly used in fields such as machine \"\n",
      "             'learning, medical diagnosis, and finance to make decisions based '\n",
      "             'on uncertain information.',\n",
      "  'role': 'user'},\n",
      " {'content': \"That's a great explanation of Bayes' theorem! It's a powerful \"\n",
      "             'tool that can be applied in various real-world scenarios to make '\n",
      "             'informed decisions. If you have any more questions or need '\n",
      "             'further clarification on this topic or anything else, feel free '\n",
      "             'to ask!',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Thank you! I'm glad you found the explanation helpful. If you \"\n",
      "             'have any more questions about mathematics or any other topic, '\n",
      "             \"please feel free to ask. I'm here to help!\",\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 315,\n",
      "                                                             'cost': 0.000871,\n",
      "                                                             'prompt_tokens': 797,\n",
      "                                                             'total_tokens': 1112},\n",
      "                                      'total_cost': 0.000871},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 315,\n",
      "                                                             'cost': 0.000871,\n",
      "                                                             'prompt_tokens': 797,\n",
      "                                                             'total_tokens': 1112},\n",
      "                                      'total_cost': 0.000871}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat termination\n",
    "- pre-defined(speicify parameters in initiate chat)\n",
    "- configure an agent to trigger termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogen Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\bigya\\AppData\\Local\\Temp\\ipykernel_22412\\328238289.py:11: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  work_dir= \"\\content\\current\" # use this temporary directory to store the code\n",
      "C:\\Users\\bigya\\AppData\\Local\\Temp\\ipykernel_22412\\328238289.py:11: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  work_dir= \"\\content\\current\" # use this temporary directory to store the code\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '\\\\content\\\\current'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m temp_dir \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# create a local command line code executor\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[43mLocalCommandLineCodeExecutor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# timeout for each code execution in seconds\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcurrent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# use this temporary directory to store the code\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m code_executor_agent \u001b[38;5;241m=\u001b[39m ConversableAgent(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_executor_agent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# turn of llm for this agent\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     code_execution_config\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecutor\u001b[39m\u001b[38;5;124m'\u001b[39m: executor},\n\u001b[0;32m     18\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32me:\\LLM\\Auto-Gen\\Autogen_project\\autogen_venv\\Lib\\site-packages\\autogen\\coding\\local_commandline_code_executor.py:121\u001b[0m, in \u001b[0;36mLocalCommandLineCodeExecutor.__init__\u001b[1;34m(self, timeout, virtual_env_context, work_dir, functions, functions_module, execution_policies)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule name must be a valid Python identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functions_module \u001b[38;5;241m=\u001b[39m functions_module\n\u001b[1;32m--> 121\u001b[0m \u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m timeout\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_work_dir: Path \u001b[38;5;241m=\u001b[39m work_dir\n",
      "File \u001b[1;32me:\\LLM\\Auto-Gen\\Autogen_project\\autogen_venv\\Lib\\pathlib.py:1312\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1312\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '\\\\content\\\\current'"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "# create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# create a local command line code executor\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout= 10, # timeout for each code execution in seconds\n",
    "    work_dir= \"\\content\\current\" # use this temporary directory to store the code\n",
    ")\n",
    "\n",
    "code_executor_agent = ConversableAgent(\n",
    "    'code_executor_agent',\n",
    "    llm_config= False, # turn of llm for this agent\n",
    "    code_execution_config= {'executor': executor},\n",
    "    human_input_mode= \"ALWAYS\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
